"""Callback functors to imbue condensation process with additional data."""

import itertools
import warnings

import scipy
import numpy as np

from abc import ABC
from abc import abstractmethod

from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors


from ripser import Ripser
from utilities import UnionFind


class Callback(ABC):
    """Generic callback class."""

    @abstractmethod
    def __call__(self, t, X, P, D):
        """Update function for a single diffusion condensation step.

        This is the main update function that is called in each step of
        the diffusion condensation process.

        Parameters
        ----------
        t : int
            Current iteration step of the diffusion condensation
            process. The callback is allowed to use this for any
            form of bookkeeping.

        X : np.array
            Current set of data points, with samples being in the rows,
            and dimensions being in the columns. Each iteration step is
            allowed to update `X`, so the callback may want to cache it
            in case operations pertain to past versions.

        P : np.array
            Transition matrix arising from the diffusion process.

        D : np.array
            Matrix of pairwise Euclidean distances between samples from
            X. This is provided for convenience purposes.
        """
        pass

    def finalise(self, data):
        """Finalise callback processing and update data dictionary.

        Tells the callback to finalise data processing and provides
        a way to optionally update the data dictionary, thus making
        it possible to store data generated by the callback.

        The default implementation performs just a pass-through.

        Parameters
        ----------
        data : dict
            Data dictionary. Contains keys generated by the diffusion
            process and other callbacks.

        Returns
        -------
        Updated data dictionary.
        """
        return data


class CalculatePersistentHomology(Callback):
    """Persistent homology calculation callback.

    This class keeps track of homology classes arising during the
    condensation process. It uses a Vietoris--Rips filtration for
    each time step to obtain persistent homology information over
    scales and time steps.

    This considers the underlying point cloud as a dynamic metric
    space.
    """

    def __init__(self, dimension=1, max_cardinality=512):
        """Build new instance of callback and set parameters.

        Parameters
        ----------
        dimension : int
            Maximum dimension for which to calculate topological
            features.

        max_cardinality : int
            Maximum cardinality of point clouds for which topological
            features should be calculated. Since calculating features
            slows down other computations, larger point clouds should
            be handled differently.
        """
        self.dimension = dimension
        self.max_cardinality = max_cardinality
        self.persistence_pairs = dict()
        self.persistence_points = dict()

    def __call__(self, t, X, P, D):
        """Update function for this functor."""
        # Nothing to do here if the point cloud is too large.
        if len(X) > self.max_cardinality:
            return

        # Calculate topological features alongside the diffusion
        # process. These are features generated by the intrinsic
        # geometry of the diffusion process.
        #
        # The Ripser class will return persistence pairs *and* a
        # set of persistence points, i.e. coordinates/distances.
        tuples, points = Ripser(dimension=self.dimension)(D)

        # Skip processing if we are unable to get some topological
        # features. This could be caused, for instance, by missing
        # `ripser` binaries.
        if tuples is None or points is None:
            print("Ripser not working")
            return

        # Add additional information about the dimension of each
        # topological feature.
        dimension = np.asarray([len(c) - 1 for c, _ in tuples])

        # Adds the dimension as an additional column, turning the 2D
        # points of the diagram into 3D points.
        points = np.column_stack((points, dimension))

        self.persistence_pairs[t] = tuples
        self.persistence_points[t] = points

    def __repr__(self):
        """Return name of callback."""
        return "CalculatePersistentHomology"

    def finalise(self, data):
        """Update data dictionary."""
        data.update(
            {
                f"persistence_pairs_t_{i}": pairs
                for i, pairs in self.persistence_pairs.items()
            }
        )

        data.update(
            {
                f"persistence_points_t_{i}": pairs
                for i, pairs in self.persistence_points.items()
            }
        )

        return data


class CalculateDiffusionHomology(Callback):
    """Diffusion homology calculation callback.

    This class keeps track of homology classes arising during the
    condensation process. This calculation is the natural analogy
    to persistent homology, but instead of filtrating over scales
    we filtrate over time steps.
    """

    def __init__(self, threshold=1e-3):
        """Create new instance.

        Parameters
        ----------
        threshold : float
            Specifies a threshold for the merges. If a pair of points is
            closer than this threshold, it will be merged.
        """
        self.persistence_pairs = []
        self.edges = []
        self.uf = None
        self.threshold = threshold
        self.distances = None
        self.reset_distances = False

    def __call__(self, t, X, P, D):
        """Update function for this functor."""
        if self.uf is None:
            self.uf = UnionFind(X.shape[0])

        if self.distances is None:
            self.distances = np.full_like(D, np.inf)

        # Reset distances for all points that are *above* the specified
        # distance threshold again. Our distance shall reflect the time
        # at which the points *remain* within this distance.
        if self.reset_distances:
            mask = np.transpose(np.nonzero(D >= self.threshold))
            self.distances[mask] = np.inf

        for i1, i2 in np.transpose(np.nonzero(D < self.threshold)):

            # Update distances of the two pairs. This corresponds to
            # their diffusion merge distance, i.e. the first time at
            # which the points should be merged.
            if not np.isfinite(self.distances[i1, i2]):
                self.distances[i1, i2] = t
                self.distances[i2, i1] = t

            if i1 > i2 and self.uf.find(i1) != self.uf.find(i2):
                younger, older = self.uf.find(i1), self.uf.find(i2)

                # Store edge; the order does not really matter here
                # but it should be consistent.
                if younger < older:
                    younger, older = older, younger

                self.edges.append((t, younger, older))

                self.uf.merge(i1, i2)

                # On the connected component level, the addition of
                # this pair is easy because *everything* is created
                # at t = 0.
                self.persistence_pairs.append((0, t))

        # Ensure that all self distances are zero. We only do this once
        # and do not care about the entries during the iteration above.
        np.fill_diagonal(self.distances, 0.0)

    def __repr__(self):
        """Return name of callback."""
        return "CalculateDiffusionHomology"

    def finalise(self, data):
        """Update data dictionary."""
        T = np.max(np.ma.masked_invalid(self.distances))
        self.distances[np.isinf(self.distances)] = T

        data.update(
            {
                "diffusion_homology_persistence_pairs": np.asarray(
                    self.persistence_pairs
                ),
                "diffusion_homology_edges": np.asarray(self.edges),
                "diffusion_homology_distances": self.distances,
            }
        )

        # Calculate Betti curve over all diffusion iteration steps
        if len(self.persistence_pairs) > 0:
            betti = [
                (t, np.sum(np.asarray(self.persistence_pairs)[:, 1] >= t))
                for t in np.arange(0, T + 1)
            ]

            data.update(
                {
                    "diffusion_homology_betti": np.asarray(betti),
                }
            )

        return data
